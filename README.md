## **Data lake purpose:**
A startup called Sparkify has an application which provides songs streaming 
capability for the users. The app produce json logs, which contain the 
user activities on the app. The startup wants to understand their users by
analyzing these logs and perform various queries on them easily. 
One of their goals to know what songs are being listened by their users.

## **Data lake structure:**

The data lake contains the following folders which hold the parquet files produced by the etl script:

- **SONGPLAYS:** This is the main folder. It contains song playing 
       transactions generated by the app according to what song has been 
       choosen and played by the user. The data partitioned in folders by year then month.
       The following are the columns and their description:
  
       - START_TIME: The timestamp in millisecond for the transaction.
       - USER_ID: The user id for the user who generated this transaction.
         It is a foreign key from the USERS table.
       - LEVEL: The type of the user either free or paid. It holds the 
         level of the user at the timestamp of this transaction.  
       - SONG_ID: The id of the song which has been played by the user.
         It is a foreign key from the SONGS table.
       - ARTIST_ID: The is of the artist for the song played.
         It is a foreign key from ARTISTS table.
       - SESSION_ID: Id for the web session which user was using and resulted
         in generating this transaction.
       - USER_AGENT: text which specify the OS type and version and browser     
         version and type. 
       - LOCATION: text which specify the location of the user 
  
- **ARTISTS:** This folder holds list of artists and any information
      related to them.
      The following are the columns and their description:
  
      - ARTIST_ID: Unique id for the artist.
      - NAME: Name of the artist.
      - LOCATION: The location of the artist geographically.
      - LATITUDE: The latitude of for the artist location. 
      - LONGITUDE: The longitude of the artist location.
    
- **SONGS:** This table holds list of songs and any information related to them.
      The following are the columns and their description:
  
      - SONG_ID: Unique id for the song.
      - TITLE: The title of name of the song.
      - ARTIST_ID: The id of the artist of this song.
      - YEAR: The production year of this song. 
      - DURATION: The playing duration of the song.
    
- **TIME:** This folder contains parquet files for all the timestamps appeared in the transactions 
      loaded in the SONGPLAYS folder. It contains additional columns
      derived from the timestamp column itself. These can be used to get 
      insights on different levels (hour,day,week,weekday,month,year).

- **USERS:** This folder holds all the users who generated any song 
      playing transaction.The following are the columns and their description:
  
      - USER_ID: Unique Id for the user.
      - FIRST_NAME:The first name for the user.
      - LAST_NAME: The last name for the user.
      - GENDER: the gender of the user(M:male,F:female)
      - LEVEL: The type of the user either free or paid. This column holds the
        latest level for the user appeared into the last log file loaded.
 
## **Files and description**

 - **[etl.py](/etl.py)**: It runs the whole ETL process. It contains two main functions: 
   one for processing the songs data and the other for processing the log data.
 - **[dl.cfg](/dl.cfg)**: This file contains any properties needed to connect to S3.

## **Sequence of execution**
 1- Add the the Access key and secret key in the dl.cfg file.

 2- Execute etl.py to run whole process and create the folders mentioned above.

